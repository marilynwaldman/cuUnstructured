{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  do this https://datascience-enthusiast.com/Python/hivesparkpython.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Untitled.ipynb', '.ipynb_checkpoints']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.listdir(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.enableHiveSupport().getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Untitled.ipynb', '.ipynb_checkpoints']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Untitled.ipynb', '.ipynb_checkpoints']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n",
      "|databaseName|\n",
      "+------------+\n",
      "|     default|\n",
      "+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('show databases').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+-----------+\n",
      "|database|tableName|isTemporary|\n",
      "+--------+---------+-----------+\n",
      "+--------+---------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('show tables').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "296"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fncs =  spark.sql('show functions').collect()\n",
    "len(fncs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "explode\n",
      "explode_outer\n",
      "expm1\n",
      "factorial\n",
      "filter\n",
      "find_in_set\n",
      "first\n",
      "first_value\n",
      "flatten\n",
      "float\n",
      "floor\n"
     ]
    }
   ],
   "source": [
    "for i in fncs[100:111]:\n",
    "    print(i[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------------------------------------------------------------------+\n",
      "|function_desc                                                                                        |\n",
      "+-----------------------------------------------------------------------------------------------------+\n",
      "|Function: instr                                                                                      |\n",
      "|Class: org.apache.spark.sql.catalyst.expressions.StringInstr                                         |\n",
      "|Usage: instr(str, substr) - Returns the (1-based) index of the first occurrence of `substr` in `str`.|\n",
      "+-----------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"describe function instr\").show(truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql('create database movies')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n",
      "|databaseName|\n",
      "+------------+\n",
      "|     default|\n",
      "|      movies|\n",
      "+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('show databases').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql('use movies')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql('create table movies \\\n",
    "         (movieId int,title string,genres string) \\\n",
    "         row format delimited fields terminated by \",\"\\\n",
    "         stored as textfile')                                              # in textfile format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"create table ratings\\\n",
    "           (userId int,movieId int,rating float,timestamp string)\\\n",
    "           stored as ORC\" )                                                # in ORC format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"create table genres_by_count\\\n",
    "           ( genres string,count int)\\\n",
    "           stored as AVRO\" )                                               # in AVRO format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------------+-----------+\n",
      "|database|      tableName|isTemporary|\n",
      "+--------+---------------+-----------+\n",
      "|  movies|genres_by_count|      false|\n",
      "|  movies|         movies|      false|\n",
      "|  movies|        ratings|      false|\n",
      "+--------+---------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"show tables\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------+--------------------------------------------------------+-------+\n",
      "|col_name                    |data_type                                               |comment|\n",
      "+----------------------------+--------------------------------------------------------+-------+\n",
      "|userId                      |int                                                     |null   |\n",
      "|movieId                     |int                                                     |null   |\n",
      "|rating                      |float                                                   |null   |\n",
      "|timestamp                   |string                                                  |null   |\n",
      "|                            |                                                        |       |\n",
      "|# Detailed Table Information|                                                        |       |\n",
      "|Database                    |movies                                                  |       |\n",
      "|Table                       |ratings                                                 |       |\n",
      "|Owner                       |jovyan                                                  |       |\n",
      "|Created Time                |Thu Dec 06 03:45:51 UTC 2018                            |       |\n",
      "|Last Access                 |Thu Jan 01 00:00:00 UTC 1970                            |       |\n",
      "|Created By                  |Spark 2.4.0                                             |       |\n",
      "|Type                        |MANAGED                                                 |       |\n",
      "|Provider                    |hive                                                    |       |\n",
      "|Table Properties            |[transient_lastDdlTime=1544067951]                      |       |\n",
      "|Location                    |file:/home/jovyan/hive/spark-warehouse/movies.db/ratings|       |\n",
      "|Serde Library               |org.apache.hadoop.hive.ql.io.orc.OrcSerde               |       |\n",
      "|InputFormat                 |org.apache.hadoop.hive.ql.io.orc.OrcInputFormat         |       |\n",
      "|OutputFormat                |org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat        |       |\n",
      "|Storage Properties          |[serialization.format=1]                                |       |\n",
      "+----------------------------+--------------------------------------------------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"describe formatted ratings\").show(truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"load data local inpath 'data/movies.csv'\\\n",
    "                 overwrite into table movies\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "\n",
    "schema = StructType([\n",
    "             StructField('userId', IntegerType()),\n",
    "             StructField('movieId', IntegerType()),\n",
    "             StructField('rating', DoubleType()),\n",
    "             StructField('timestamp', StringType())\n",
    "            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_df = spark.read.csv(\"data/ratings.csv\", schema = schema, header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- userId: integer (nullable = true)\n",
      " |-- movieId: integer (nullable = true)\n",
      " |-- rating: double (nullable = true)\n",
      " |-- timestamp: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ratings_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+----------+\n",
      "|userId|movieId|rating| timestamp|\n",
      "+------+-------+------+----------+\n",
      "|     1|    307|   3.5|1256677221|\n",
      "|     1|    481|   3.5|1256677456|\n",
      "|     1|   1091|   1.5|1256677471|\n",
      "|     1|   1257|   4.5|1256677460|\n",
      "|     1|   1449|   4.5|1256677264|\n",
      "+------+-------+------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ratings_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "from pyspark import SparkContext, SparkConf\n",
    "\n",
    "conf = SparkConf().setMaster(\"local[*]\")\n",
    "sc = SparkContext.getOrCreate(conf)\n",
    "\n",
    "rdd = sc.textFile(\"data/ratings.csv\")\n",
    "header = rdd.first()\n",
    "ratings_df2 = rdd.filter(lambda line: line != header).map(lambda line: Row(userId = int(line.split(\",\")[0]),\n",
    "                                                                     movieId = int(line.split(\",\")[1]),\n",
    "                                                                     rating = float(line.split(\",\")[2]),\n",
    "                                                                     timestamp = line.split(\",\")[3]\n",
    "                                                                    )).toDF()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd2 = rdd.filter(lambda line: line != header).map(lambda line:line.split(\",\"))\n",
    "ratings_df2_b =spark.createDataFrame(rdd2, schema = schema) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- movieId: long (nullable = true)\n",
      " |-- rating: double (nullable = true)\n",
      " |-- timestamp: string (nullable = true)\n",
      " |-- userId: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ratings_df2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+----------+------+\n",
      "|movieId|rating| timestamp|userId|\n",
      "+-------+------+----------+------+\n",
      "|    307|   3.5|1256677221|     1|\n",
      "|    481|   3.5|1256677456|     1|\n",
      "|   1091|   1.5|1256677471|     1|\n",
      "|   1257|   4.5|1256677460|     1|\n",
      "|   1449|   4.5|1256677264|     1|\n",
      "+-------+------+----------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ratings_df2.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_df.createOrReplaceTempView(\"ratings_df_table\") # we can also use registerTempTable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"insert into table ratings select * from ratings_df_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------------------------------+-------------------------------------------+\n",
      "|movieId|title                             |genres                                     |\n",
      "+-------+----------------------------------+-------------------------------------------+\n",
      "|null   |title                             |genres                                     |\n",
      "|1      |Toy Story (1995)                  |Adventure|Animation|Children|Comedy|Fantasy|\n",
      "|2      |Jumanji (1995)                    |Adventure|Children|Fantasy                 |\n",
      "|3      |Grumpier Old Men (1995)           |Comedy|Romance                             |\n",
      "|4      |Waiting to Exhale (1995)          |Comedy|Drama|Romance                       |\n",
      "|5      |Father of the Bride Part II (1995)|Comedy                                     |\n",
      "|6      |Heat (1995)                       |Action|Crime|Thriller                      |\n",
      "|7      |Sabrina (1995)                    |Comedy|Romance                             |\n",
      "|8      |Tom and Huck (1995)               |Adventure|Children                         |\n",
      "|9      |Sudden Death (1995)               |Action                                     |\n",
      "+-------+----------------------------------+-------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from movies limit 10\").show(truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+----------+\n",
      "|userId|movieId|rating|timestamp |\n",
      "+------+-------+------+----------+\n",
      "|1     |307    |3.5   |1256677221|\n",
      "|1     |481    |3.5   |1256677456|\n",
      "|1     |1091   |1.5   |1256677471|\n",
      "|1     |1257   |4.5   |1256677460|\n",
      "|1     |1449   |4.5   |1256677264|\n",
      "|1     |1590   |2.5   |1256677236|\n",
      "|1     |1591   |1.5   |1256677475|\n",
      "|1     |2134   |4.5   |1256677464|\n",
      "|1     |2478   |4.0   |1256677239|\n",
      "|1     |2840   |3.0   |1256677500|\n",
      "+------+-------+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from ratings limit 10\").show(truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|              genres|count|\n",
      "+--------------------+-----+\n",
      "|               Drama|   18|\n",
      "|         The (1995)\"|   18|\n",
      "|       Drama|Romance|   13|\n",
      "|              Comedy|   13|\n",
      "|        Comedy|Drama|   11|\n",
      "|      Comedy|Romance|   10|\n",
      "|         Documentary|   10|\n",
      "|Comedy|Drama|Romance|    4|\n",
      "|Action|Crime|Thri...|    3|\n",
      "|         Crime|Drama|    3|\n",
      "|Action|Sci-Fi|Thr...|    3|\n",
      "+--------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select genres, count(*) as count from movies\\\n",
    "          group by genres\\\n",
    "          having count(*) > 2 \\\n",
    "          order by count desc\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"insert into table genres_by_count \\\n",
    "          select genres, count(*) as count from movies\\\n",
    "          group by genres\\\n",
    "          having count(*) >= 2 \\\n",
    "          order by count desc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----+\n",
      "|       genres|count|\n",
      "+-------------+-----+\n",
      "|        Drama|   18|\n",
      "|  The (1995)\"|   18|\n",
      "|Drama|Romance|   13|\n",
      "+-------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from genres_by_count order by count desc limit 3\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- userId: integer (nullable = true)\n",
      " |-- movieId: integer (nullable = true)\n",
      " |-- tag: string (nullable = true)\n",
      " |-- timestamp: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "schema = StructType([\n",
    "             StructField('userId', IntegerType()),\n",
    "             StructField('movieId', IntegerType()),\n",
    "             StructField('tag', StringType()),\n",
    "             StructField('timestamp', StringType())\n",
    "            ])\n",
    "\n",
    "tags_df = spark.read.csv(\"data/tags.csv\", schema = schema, header = True)\n",
    "tags_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_df.registerTempTable('tags_df_table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------------+-----------+\n",
      "|database|       tableName|isTemporary|\n",
      "+--------+----------------+-----------+\n",
      "|  movies| genres_by_count|      false|\n",
      "|  movies|          movies|      false|\n",
      "|  movies|         ratings|      false|\n",
      "|        |ratings_df_table|       true|\n",
      "|        |   tags_df_table|       true|\n",
      "+--------+----------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('show tables').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined = spark.sql(\"select m.title, m.genres, r.movieId, r.userId,  r.rating, r.timestamp as ratingTimestamp, \\\n",
    "               t.tag, t.timestamp as tagTimestamp from ratings as r\\\n",
    "               inner join tags_df_table as t\\\n",
    "               on r.movieId = t.movieId and r.userId = t.userId \\\n",
    "               inner join movies as m on r.movieId = m.movieId\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(joined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+------+\n",
      "|title|genres|rating|\n",
      "+-----+------+------+\n",
      "+-----+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "joined.select(['title','genres','rating']).show(5, truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/hive\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
